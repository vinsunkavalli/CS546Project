# -*- coding: utf-8 -*-
"""metrics.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZGefx9CyU6HDZOemA8PXgcroGM7t1Ker
"""

def get_metrics_sentence(predictions, labels):
  assert len(predictions) == len(labels)

  tp = 0
  fp = 0
  fn = 0
  tn = 0

  for i in range(len(predictions)):
    prediction = predictions[i]
    label = labels[i]

    prediction = prediction.split(" ")
    label = label.split(" ")

    for i in range(len(label)):
      if len(prediction) <= i or prediction[i] == "O":
        if label[i] == "O":
          tn += 1
        else:
          fn += 1
      else:
        if prediction[i] == label[i]:
          tp += 1
        else:
          fp += 1

  return tp, fp, fn, tn

import json

baseline = None

with open("baseline_conll_test.json", "r") as infile:
  baseline = json.load(infile)

print(baseline)

predictions = baseline["predictions"]
labels = baseline["labels"]

tp, fp, fn, tn = get_metrics_sentence(predictions, labels)

print(tp, fp, fn, tn)

precision = tp / (tp + fp)
recall = tp / (tp + fn)
f1 = (2 * precision * recall)/(precision + recall)
accuracy = (tp + tn)/(tp + tn + fp + fn)

print(precision, recall, f1, accuracy)

knn = None

with open("knn_conll_test.json", "r") as infile:
  knn = json.load(infile)

predictions = knn["predictions"]
labels = knn["labels"]

tp, fp, fn, tn = get_metrics_sentence(predictions, labels)

precision = tp / (tp + fp)
recall = tp / (tp + fn)
f1 = (2 * precision * recall)/(precision + recall)
accuracy = (tp + tn)/(tp + tn + fp + fn)

print(precision, recall, f1, accuracy)

test_data = None

with open("wnut_test.json", "r") as infile:
  test_data = json.load(infile)

print(test_data["sentences"][0])

num_tokens = []

for i in range(len(test_data["sentences"])):
  num_tokens.append(len(test_data["sentences"][i]["sentence"].split(" ")))

print(num_tokens)
print(len(num_tokens))

def get_metrics_dict(predictions, labels, num_tokens):
  assert len(predictions) == len(labels)

  tp = 0
  fp = 0
  fn = 0
  tn = 0

  for i in range(len(predictions)):
    prediction = predictions[i]
    label = labels[i]

    total = num_tokens[i]

    ttp = 0
    tfn = 0
    tfp = 0

    for tag in label.keys():
      for token in label[tag]:
        if tag in prediction.keys() and token in prediction[tag]:
          ttp += 1
        else:
          tfn += 1
      if tag in prediction.keys():
        for token in prediction[tag]:
          if token not in label[tag]:
            tfp += 1

    tn += total - ttp - tfn - tfp
    tp += ttp
    fn += tfn
    fp += tfp

  return tp, fp, fn, tn

qa_zero_shot = None

with open("qa_full_wnut.json", "r") as infile:
  qa_zero_shot = json.load(infile)

predictions = qa_zero_shot["predictions"]
labels = [datum["entities"] for datum in test_data["sentences"]] [:1284]

print(len(predictions))
print(labels)

tp, fp, fn, tn = get_metrics_dict(predictions, labels, num_tokens)

print(tp, fp, fn, tn)

precision = tp / (tp + fp)
recall = tp / (tp + fn)
f1 = (2 * precision * recall)/(precision + recall)
accuracy = (tp + tn)/(tp + tn + fp + fn)

print(precision, recall, f1, accuracy)

qa_zero_shot = None

with open(".json", "r") as infile:
  qa_zero_shot = json.load(infile)

predictions = qa_zero_shot["predictions"]
labels = qa_zero_shot["labels"]

tp, fp, fn, tn = get_metrics_dict(predictions, labels, num_tokens)

print(tp, fp, fn, tn)

precision = tp / (tp + fp)
recall = tp / (tp + fn)
f1 = (2 * precision * recall)/(precision + recall)
accuracy = (tp + tn)/(tp + tn + fp + fn)

print(precision, recall, f1, accuracy)

without_domain = None

with open("task_modification_wnut_result.json", "r") as infile:
  without_domain = json.load(infile)

print(len(without_domain["labels"]))

print(without_domain["predictions"][0])

def str_to_dict(string):
    string = string.replace("'corporation'", "\"corporation\"")
    string = string.replace("'creative-work'", "\"creative-work\"")
    string = string.replace("'group'", "\"group\"")
    string = string.replace("'location'", "\"location\"")
    string = string.replace("'person'", "\"person\"")
    string = string.replace("'product'", "\"product\"")

    string = string.replace("{'", "{\"")
    string = string.replace("':", "\":")

    string = string.replace("['", "[\"")
    string = string.replace(", '", ", \"")
    string = string.replace("', ", "\", ")
    string = string.replace("']", "\"]")

    string = string.replace(" \" ", " ' ")
    string = string.replace("\"\"", "\"")

    res = {"corporation": [], "creative-work": [], "group": [], "location": [], "person": [], "product": []}

    try:
      res = eval(string)
    except:
      print(string)

    return res

without_domain["predictions"] = [str_to_dict(pred) for pred in without_domain["predictions"]]

predictions = without_domain["predictions"]
labels = without_domain["labels"]

tp, fp, fn, tn = get_metrics_dict(predictions, labels, num_tokens)

print(tp, fp, fn, tn)

precision = tp / (tp + fp)
recall = tp / (tp + fn)
f1 = (2 * precision * recall)/(precision + recall)
accuracy = (tp + tn)/(tp + tn + fp + fn)

print(precision, recall, f1, accuracy)

with_domain = None

with open("with_domain_task_modification_wnut_result.json", "r") as infile:
  with_domain = json.load(infile)

with_domain["predictions"] = [str_to_dict(pred) for pred in with_domain["predictions"]]

predictions = with_domain["predictions"]
labels = with_domain["labels"]

print(len(predictions))

tp, fp, fn, tn = get_metrics_dict(predictions, labels, num_tokens)

print(tp, fp, fn, tn)

precision = tp / (tp + fp)
recall = tp / (tp + fn)
f1 = (2 * precision * recall)/(precision + recall)
accuracy = (tp + tn)/(tp + tn + fp + fn)

print(precision, recall, f1, accuracy)

